{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG_19_TensorFlow_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvrsvara/2032-VARA-RAGHAVA-SAI/blob/master/VGG_19_TensorFlow_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "axvJWOQKQ0Dv",
        "outputId": "2f9b09d8-b938-4999-d3c4-9417744028e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KEJtnUNhGrw"
      },
      "source": [
        "import os\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path=\"/content/gdrive/MyDrive/colab notebook/data/train\"\n",
        "test_path=\"/content/gdrive/MyDrive/colab notebook/data/test\"\n",
        "class_names=os.listdir(train_path)\n",
        "class_names_test=os.listdir(test_path)"
      ],
      "metadata": {
        "id": "fGphX6oJRGpv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.layers import *\n",
        "from keras.models import * \n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "rpHbUn8RmnIi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (224,224,3)\n",
        "VGG16_MODEL=tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "id": "oV7iy_98msJ7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16_MODEL.trainable=False\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "prediction_layer = tf.keras.layers.Dense(4,activation='softmax')"
      ],
      "metadata": {
        "id": "deXlFsbemsqV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.isdir('models'):\n",
        "    os.mkdir('models')\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.05\n",
        "        )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/colab notebook/data/train',\n",
        "        target_size=(224,224),\n",
        "        batch_size=256,\n",
        "        class_mode='categorical',\n",
        "        subset='training'\n",
        "        )"
      ],
      "metadata": {
        "id": "etuWIeJ8mwPw",
        "outputId": "efc7eb54-656b-446b-df3b-acf86e16c5e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5370 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/colab notebook/data/test',\n",
        "        target_size=(224,224),\n",
        "        batch_size=256,\n",
        "        class_mode='categorical',\n",
        "        subset='validation'\n",
        "        )"
      ],
      "metadata": {
        "id": "pIK1cT_QnBeG",
        "outputId": "29333e3a-af8a-4435-e921-ced9bb73071a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 72 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/content/gdrive/MyDrive/colab notebook/data/test',\n",
        "        target_size=(224,224),\n",
        "        batch_size=256,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "cxJq6sGXnDtS",
        "outputId": "d556fa02-e51b-4cbf-e7bf-4a2a4024659c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1488 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "  VGG16_MODEL,\n",
        "  global_average_layer,\n",
        "  prediction_layer\n",
        "])"
      ],
      "metadata": {
        "id": "D0zUjf6onuXd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "wQ3AYoGroK9B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,validation_data=val_generator,epochs=15)"
      ],
      "metadata": {
        "id": "PQ9PVj13oMsz",
        "outputId": "07c854bd-db14-4160-ee39-432d58441400",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "21/21 [==============================] - 2699s 128s/step - loss: 1.5014 - accuracy: 0.2737 - val_loss: 1.0794 - val_accuracy: 0.5833\n",
            "Epoch 2/15\n",
            "21/21 [==============================] - 2675s 127s/step - loss: 1.0116 - accuracy: 0.6048 - val_loss: 1.0173 - val_accuracy: 0.5833\n",
            "Epoch 3/15\n",
            "21/21 [==============================] - 2695s 128s/step - loss: 0.9526 - accuracy: 0.6048 - val_loss: 0.9697 - val_accuracy: 0.5833\n",
            "Epoch 4/15\n",
            " 3/21 [===>..........................] - ETA: 37:52 - loss: 0.9124 - accuracy: 0.6185"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LLxOu_bIoO4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "-sxTvMKeJqTD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}